{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f6469b",
   "metadata": {},
   "source": [
    "# AIG 230 â€“ Week 2 Lab\n",
    "## From Raw Text to Corpus: Tokenization, Normalization, and Vocabulary\n",
    "\n",
    "Industry Context: Exploring the State of the Union Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d1b9c",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Understand raw text, documents, and corpora\n",
    "- Explore a real-world corpus\n",
    "- Compare NLTK and spaCy preprocessing pipelines\n",
    "- Perform tokenization, normalization, and vocabulary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a390dee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"state_union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1368c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.0/12.8 MB 16.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 29.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 32.2 MB/s  0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy English model\n",
    "# Run once if needed:\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df6847",
   "metadata": {},
   "source": [
    "Breaking it down:\n",
    "\n",
    "```\n",
    "spacy.load() - loads a pre-trained language model\n",
    "```\n",
    "\n",
    "\"en_core_web_sm\" - the small English model that includes:\n",
    "\n",
    "- Tokenizer - splits text into words/sentences\n",
    "- Part-of-speech tagger - identifies noun, verb, adjective, etc.\n",
    "- Dependency parser - analyzes grammatical relationships\n",
    "- Named entity recognizer - identifies people, places, organizations\n",
    "- Word vectors - semantic meaning of words\n",
    "\n",
    "nlp = - stores the loaded model in a variable so you can use it to process text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d0066",
   "metadata": {},
   "source": [
    "## Part 1 â€“ Obtaining the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa16697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import state_union\n",
    "state_union.fileids()[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d7ee5",
   "metadata": {},
   "source": [
    "Each file is a document. The collection is the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e529d0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(state_union.fileids())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc584e2",
   "metadata": {},
   "source": [
    "## Part 2 â€“ Inspect Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11505dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\\n \\nApril 16, 1945\\n\\nMr. Speaker, Mr. President, Members of the Congress:\\nIt is with a heavy heart that I stand before you, my friends and colleagues, in the Congress of the United States.\\nOnly yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt. At a time like this, words are inadequate. The most eloquent tribute would be a reverent silence.\\nYet, in this decisive hour, when world events are moving so rapidly, our silence might be misunderstood and might give comfort to our enemies.\\nIn His infinite wisdom, Almighty God has seen fit to take from us a great man who loved, and was beloved by, all humanity.\\nNo man could possibly fill the tremendous void left by the passing of that noble soul. No words can ease the aching hearts of untold millions of every race, creed and color. The world knows it has lost a heroic champion of justice and freedom.\\nTragic fate has thrust upon\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample_file = state_union.fileids()[0]\n",
    "raw_text = state_union.raw(sample_file)\n",
    "raw_text[:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172ef1a",
   "metadata": {},
   "source": [
    "## Part 3 â€“ Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175db979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'S.',\n",
       " 'TRUMAN',\n",
       " \"'S\",\n",
       " 'ADDRESS',\n",
       " 'BEFORE',\n",
       " 'A',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " '16',\n",
       " ',',\n",
       " '1945',\n",
       " 'Mr.',\n",
       " 'Speaker',\n",
       " ',',\n",
       " 'Mr.',\n",
       " 'President',\n",
       " ',',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Congress',\n",
       " ':',\n",
       " 'It',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " ',',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens_nltk = word_tokenize(raw_text)\n",
    "tokens_nltk[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "222b287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\n",
       " \n",
       "April 16, 1945\n",
       "\n",
       "Mr. Speaker, Mr. President, Members of the Congress:\n",
       "It is with a heavy heart that I stand before you, my friends and colleagues, in the Congress of the United States.\n",
       "Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt. At a time like this, words are inadequate. The most eloquent tribute would be a reverent silence.\n",
       "Yet, in this decisive hour, when world events are moving so rapidly, our silence might be misunderstood and might give comfort to our enemies.\n",
       "In His infinite wisdom, Almighty God has seen fit to take from us a great man who loved, and was beloved by, all humanity.\n",
       "No man could possibly fill the tremendous void left by the passing of that noble soul. No words can ease the aching hearts of untold millions of every race, creed and color. The world knows it has lost a heroic champion of justice and freedom.\n",
       "Tragic fate has thrust upon us grave responsibilities. We must carry on.Our departed leader never looked backward. He looked forward and moved forward. That is what he would want us to do. That is what America will do.\n",
       "So much blood has already been shed for the ideals which we cherish, and for which Franklin Delano Roosevelt lived and died, that we dare not permit even a momentary pause in the hard fight for victory.\n",
       "Today, the entire world is looking to America for enlightened leadership to peace and progress. Such a leadership requires vision, courage and tolerance. It can be provided only by a united nation deeply devoted to the highest ideals.\n",
       "With great humility I call upon all Americans to help me keep our nation united in defense of those ideals which have been so eloquently proclaimed by Franklin Roosevelt.\n",
       "I want in turn to assure my fellow Americans and all of those who love peace and liberty throughout the world that I will support and defend those ideals with all my strength and all my heart. That is my duty and I shall not shirk it.\n",
       "So that there can be no possible misunderstanding, both Germany and Japan can be certain, beyond any shadow of a doubt, that America will continue the fight for freedom until no vestige of resistance remains!\n",
       "We are deeply conscious of the fact that much hard fighting is still ahead of us.\n",
       "Having to pay such a heavy price to make complete victory certain, America will never become a party to any plan for partial victory!\n",
       "To settle for merely another temporary respite would surely jeopardize the future security of all the world.\n",
       "Our demand has been, and it remains-Unconditional Surrender! We will not traffic with the breakers of the peace on the terms of the peace.\n",
       "The responsibility for making of the peace-and it is a very grave responsibility-must rest with the defenders of the peace. We are not unconscious of the dictates of humanity. We do not wish to see unnecessary or unjustified suffering. But the laws of Go d and of man have been violated and the guilty must not go unpunished. Nothing shall shake our determination to punish the war criminals even though we must pursue them to the ends of the earth.\n",
       "Lasting peace can never be secured if we permit our dangerous opponents to plot future wars with impunity at any mountain retreat - however distant.\n",
       "In this shrinking world, it is futile to seek safety behind geographical barriers. Real security will be found only in law and in justice.\n",
       "Here in America, we have labored long and hard to achieve a social order worthy of our great heritage. In our time, tremendous progress has been made toward a really democratic way of life. Let me assure the forward-looking people of America that there w ill be no relaxation in our efforts to improve the lot of the common people.\n",
       "In the difficult days ahead, unquestionably we shall face problems of staggering proportions. However, with the faith of our fathers in our hearts, we do not fear the future.\n",
       "On the battlefields, we have frequently faced overwhelming odds - and won! At home, Americans will not be less resolute! We shall never cease our struggle to preserve and maintain our American way of life.\n",
       "At this moment, America, along with her brave Allies, is paying again a heavy price for the defense of our freedom. With characteristic energy, we are assisting in the liberation of entire nations. Gradually, the shackles of slavery are being broken by t he forces of freedom.\n",
       "All of us are praying for a speedy victory. Every day peace is delayed costs a terrible toll.\n",
       "The armies of liberation today are bringing to an end Hitler's ghastly threat to dominate the world. Tokyo rocks under the weight of our bombs.\n",
       "The grand strategy of the United Nations' war has been determined - due in no small measure to the vision of our departed Commander in Chief. We are now carrying out our part of that strategy under the able direction of Admiral Leahy, General Marshall, A dmiral King, General Arnold, General Eisenhower, Admiral Nimitz and General MacArthur.\n",
       "I want the entire world to know that this direction must and will remain-unchanged and unhampered!\n",
       "Our debt to the heroic men and valiant women in the service of our country can never be repaid. They have earned our undying gratitude. America will never forget their sacrifices. Because of these sacrifices, the dawn of justice and freedom throughout th e world slowly casts its gleam across the horizon.\n",
       "Our forefathers came to our rugged shores in search of religious tolerance, political freedom and economic opportunity. For those fundamental rights, they risked their lives. We well know today that such rights can be preserved only by constant vigilance , the eternal price of liberty!\n",
       "Within an hour after I took the oath of office, I announced that the San Francisco Conference would proceed. We will face the problems of peace with the same courage that we have faced and mastered the problems of war.\n",
       "In the memory of those who have made the supreme sacrifice-in the memory of our fallen President-we shall not fail!\n",
       "It is not enough to yearn for peace. We must work, and if necessary, fight for it. The task of creating a sound international organization is complicated and difficult. Yet, without such organization, the rights of man on earth cannot be protected. Machi nery for the just settlement of international differences must be found. Without such machinery, the entire world will have to remain an armed camp. The world will be doomed to deadly conflict, devoid of hope for real peace.\n",
       "Fortunately, people have retained hope for a durable peace. Thoughtful people have always had faith that ultimately justice must triumph. Past experience surely indicates that, without justice, an enduring peace becomes impossible.\n",
       "In bitter despair, some people have come to believe that wars are inevitable. With tragic fatalism, they insist that wars have always been, of necessity, and of necessity wars always will be. To such defeatism, men and women of good will must not and can not yield. The outlook for humanity is not so hopeless.\n",
       "During the dark hours of this horrible war, entire nations were kept going by something intangible-hope! When warned that abject submission offered the only salvation against overwhelming power, hope showed the way to victory.\n",
       "Hope has become the secret weapon of the forces of liberation!\n",
       "Aggressors could not dominate the human mind. As long as hope remains, the spirit of man will never be crushed.\n",
       "But hope alone was not and is not sufficient to avert war. We must not only have hope but we must have faith enough to work with other peace-loving nations to maintain the peace. Hope was not enough to beat back the aggressors as long as the peace-loving nations were unwilling to come to each other's defense. The aggressors were beaten back only when the peace-loving nations united to defend themselves.\n",
       "If wars in the future are to be prevented the nations must be united in their determination to keep the peace under law.\n",
       "Nothing is more essential to the future peace of the world than continued cooperation of the nations which had to muster the force necessary to defeat the conspiracy of the Axis powers to dominate the world.\n",
       "While these great states have a special responsibility to enforce the peace, their responsibility is based upon the obligations resting upon all states, large and small, not to use force in international relations except in the defense of law. The respon sibility of the great states is to serve and not to dominate the world.\n",
       "To build a foundation of enduring peace we must not only work in harmony with our friends abroad, but we must have the united support of our own people.\n",
       "Even the most experienced pilot cannot bring a ship safely into harbor, unless he has the full cooperation of the crew. For the benefit of all, every individual must do his duty.\n",
       "I appeal to every American, regardless of party, race, creed, or color, to support our efforts to build a strong and lasting United Nations Organization.\n",
       "You, the Members of the Congress, surely know how I feel. Only with your help can I hope to complete one of the greatest tasks ever assigned to a public servant. With Divine guidance, and your help, we will find the new passage to a far better world, a kindly and friendly world, with just and lasting peace.\n",
       "With confidence, I am depending upon all of you.\n",
       "To destroy greedy tyrants with dreams of world domination, we cannot continue in successive generations to sacrifice our finest youth.\n",
       "In the name of human decency and civilization, a more rational method of deciding national differences must and will be found!\n",
       "America must assist suffering humanity back along the path of peaceful progress. This will require time and tolerance. We shall need also an abiding faith in the people, the kind of faith and courage which Franklin Delano Roosevelt always had!\n",
       "Today, America has become one of the most powerful forces for good on earth. We must keep it so. We have achieved a world leadership which does not depend solely upon our military and naval might.\n",
       "We have learned to fight with other nations in common defense of our freedom. We must now learn to live with other nations for our mutual good. We must learn to trade more with other nations so that there may be-for our mutual advantage-increased product ion, increased employment and better standards of living throughout the world.\n",
       "May we Americans all live up to our glorious heritage.\n",
       "In that way, America may well lead the world to peace and prosperity.\n",
       "At this moment, I have in my heart a prayer. As I have assumed my heavy duties, I humbly pray Almighty God, in the words of King Solomon:\n",
       "\"Give therefore thy servant an understanding heart to judge thy people, that I may discern between good and bad; for who is able to judge this thy so great a people?\"\n",
       "I ask only to be a good and faithful servant of my Lord and my people."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc = nlp(raw_text)\n",
    "doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13797f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_spacy = [token.text for token in doc]\n",
    "tokens_spacy[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b030c7",
   "metadata": {},
   "source": [
    "ðŸ“Œ Tokenization splits text into meaningful units (tokens).\n",
    "There is no universal standard, but conventions vary by task and language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988b99e",
   "metadata": {},
   "source": [
    "## Part 4 â€“ Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854be3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\\n \\nApril 16, 1945\\n\\nMr. Speaker, Mr. President, Members of the Congress:\\nIt is with a heavy heart that I stand before you, my friends and colleagues, in the Congress of the United States.\",\n",
       " 'Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt.',\n",
       " 'At a time like this, words are inadequate.',\n",
       " 'The most eloquent tribute would be a reverent silence.',\n",
       " 'Yet, in this decisive hour, when world events are moving so rapidly, our silence might be misunderstood and might give comfort to our enemies.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences_nltk = sent_tokenize(raw_text)\n",
    "sentences_nltk[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83d38b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\n",
       "  \n",
       " April 16, 1945\n",
       " \n",
       " Mr. Speaker, Mr. President, Members of the Congress:,\n",
       " It is with a heavy heart that I stand before you, my friends and colleagues, in the Congress of the United States.,\n",
       " Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt.,\n",
       " At a time like this, words are inadequate.,\n",
       " The most eloquent tribute would be a reverent silence.]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences_spacy = list(doc.sents)\n",
    "sentences_spacy[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e8fd7",
   "metadata": {},
   "source": [
    "## Part 5 â€“ Normalization\n",
    "Normalization makes text more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530ce0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'harry',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'before',\n",
       " 'a',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'president',\n",
       " 'members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'it',\n",
       " 'is']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "normalized_nltk = [t.lower() for t in tokens_nltk if t.isalpha()]\n",
    "normalized_nltk[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ea6d9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'harry',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'before',\n",
       " 'a',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'president',\n",
       " 'members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'it',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'i',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'only',\n",
       " 'yesterday',\n",
       " 'we',\n",
       " 'laid',\n",
       " 'to',\n",
       " 'rest',\n",
       " 'the',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'our',\n",
       " 'beloved',\n",
       " 'president',\n",
       " 'franklin',\n",
       " 'delano',\n",
       " 'roosevelt',\n",
       " 'at',\n",
       " 'a',\n",
       " 'time',\n",
       " 'like',\n",
       " 'this',\n",
       " 'words',\n",
       " 'are',\n",
       " 'inadequate',\n",
       " 'the',\n",
       " 'most',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'yet',\n",
       " 'in',\n",
       " 'this',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'when',\n",
       " 'world',\n",
       " 'events',\n",
       " 'are',\n",
       " 'moving',\n",
       " 'so',\n",
       " 'rapidly',\n",
       " 'our',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'be',\n",
       " 'misunderstood',\n",
       " 'and',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'to',\n",
       " 'our',\n",
       " 'enemies',\n",
       " 'in',\n",
       " 'his',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'almighty',\n",
       " 'god',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'to',\n",
       " 'take',\n",
       " 'from',\n",
       " 'us',\n",
       " 'a',\n",
       " 'great',\n",
       " 'man',\n",
       " 'who',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'was',\n",
       " 'beloved',\n",
       " 'by',\n",
       " 'all',\n",
       " 'humanity',\n",
       " 'no',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'passing',\n",
       " 'of',\n",
       " 'that',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'no',\n",
       " 'words',\n",
       " 'can',\n",
       " 'ease',\n",
       " 'the',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'of',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'and',\n",
       " 'color',\n",
       " 'the',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'it',\n",
       " 'has',\n",
       " 'lost',\n",
       " 'a',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'tragic',\n",
       " 'fate',\n",
       " 'has',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'we',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'that',\n",
       " 'is',\n",
       " 'what',\n",
       " 'he',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'to',\n",
       " 'do',\n",
       " 'that',\n",
       " 'is',\n",
       " 'what',\n",
       " 'america',\n",
       " 'will',\n",
       " 'do',\n",
       " 'so',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'has',\n",
       " 'already',\n",
       " 'been',\n",
       " 'shed',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'we',\n",
       " 'cherish',\n",
       " 'and',\n",
       " 'for',\n",
       " 'which',\n",
       " 'franklin',\n",
       " 'delano',\n",
       " 'roosevelt',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'died',\n",
       " 'that',\n",
       " 'we',\n",
       " 'dare',\n",
       " 'not',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'a',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'victory',\n",
       " 'today',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'america',\n",
       " 'for',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'to',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'progress',\n",
       " 'such',\n",
       " 'a',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'and',\n",
       " 'tolerance',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'only',\n",
       " 'by',\n",
       " 'a',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'with',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'i',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'americans',\n",
       " 'to',\n",
       " 'help',\n",
       " 'me',\n",
       " 'keep',\n",
       " 'our',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'in',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'by',\n",
       " 'franklin',\n",
       " 'roosevelt',\n",
       " 'i',\n",
       " 'want',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'assure',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'americans',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'world',\n",
       " 'that',\n",
       " 'i',\n",
       " 'will',\n",
       " 'support',\n",
       " 'and',\n",
       " 'defend',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'with',\n",
       " 'all',\n",
       " 'my',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'all',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'is',\n",
       " 'my',\n",
       " 'duty',\n",
       " 'and',\n",
       " 'i',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'shirk',\n",
       " 'it',\n",
       " 'so',\n",
       " 'that',\n",
       " 'there',\n",
       " 'can',\n",
       " 'be',\n",
       " 'no',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'both',\n",
       " 'germany',\n",
       " 'and',\n",
       " 'japan',\n",
       " 'can',\n",
       " 'be',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'any',\n",
       " 'shadow',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'america',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'the',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'until',\n",
       " 'no',\n",
       " 'vestige',\n",
       " 'of',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'we',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'is',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'us',\n",
       " 'having',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'such',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'to',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'america',\n",
       " 'will',\n",
       " 'never',\n",
       " 'become',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'any',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'to',\n",
       " 'settle',\n",
       " 'for',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'security',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'world',\n",
       " 'our',\n",
       " 'demand',\n",
       " 'has',\n",
       " 'been',\n",
       " 'and',\n",
       " 'it',\n",
       " 'surrender',\n",
       " 'we',\n",
       " 'will',\n",
       " 'not',\n",
       " 'traffic',\n",
       " 'with',\n",
       " 'the',\n",
       " 'breakers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'on',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'the',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'making',\n",
       " 'of',\n",
       " 'the',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'grave',\n",
       " 'rest',\n",
       " 'with',\n",
       " 'the',\n",
       " 'defenders',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'we',\n",
       " 'are',\n",
       " 'not',\n",
       " 'unconscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dictates',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'or',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'but',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'go',\n",
       " 'd',\n",
       " 'and',\n",
       " 'of',\n",
       " 'man',\n",
       " 'have',\n",
       " 'been',\n",
       " 'violated',\n",
       " 'and',\n",
       " 'the',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'not',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'our',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'punish',\n",
       " 'the',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'we',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ends',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'lasting',\n",
       " 'peace',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'secured',\n",
       " 'if',\n",
       " 'we',\n",
       " 'permit',\n",
       " 'our',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'with',\n",
       " 'impunity',\n",
       " 'at',\n",
       " 'any',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'in',\n",
       " 'this',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'it',\n",
       " 'is',\n",
       " 'futile',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'real',\n",
       " 'security',\n",
       " 'will',\n",
       " 'be',\n",
       " 'found',\n",
       " 'only',\n",
       " 'in',\n",
       " 'law',\n",
       " 'and',\n",
       " 'in',\n",
       " 'justice',\n",
       " 'here',\n",
       " 'in',\n",
       " 'america',\n",
       " 'we',\n",
       " 'have',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'and',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'of',\n",
       " 'our',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'in',\n",
       " 'our',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'has',\n",
       " 'been',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'a',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'let',\n",
       " 'me',\n",
       " 'assure',\n",
       " 'the',\n",
       " 'people',\n",
       " 'of',\n",
       " 'america',\n",
       " 'that',\n",
       " 'there',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'be',\n",
       " 'no',\n",
       " 'relaxation',\n",
       " 'in',\n",
       " 'our',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'common',\n",
       " 'people',\n",
       " 'in',\n",
       " 'the',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'however',\n",
       " 'with',\n",
       " 'the',\n",
       " 'faith',\n",
       " 'of',\n",
       " 'our',\n",
       " 'fathers',\n",
       " 'in',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fear',\n",
       " 'the',\n",
       " 'future',\n",
       " 'on',\n",
       " 'the',\n",
       " 'battlefields',\n",
       " 'we',\n",
       " 'have',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'and',\n",
       " 'won',\n",
       " 'at',\n",
       " 'home',\n",
       " 'americans',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'our',\n",
       " 'struggle',\n",
       " 'to',\n",
       " 'preserve',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'our',\n",
       " 'american',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'at',\n",
       " 'this',\n",
       " 'moment',\n",
       " 'america',\n",
       " 'along',\n",
       " 'with',\n",
       " 'her',\n",
       " 'brave',\n",
       " 'allies',\n",
       " 'is',\n",
       " 'paying',\n",
       " 'again',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'for',\n",
       " 'the',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'our',\n",
       " 'freedom',\n",
       " 'with',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'we',\n",
       " 'are',\n",
       " 'assisting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'liberation',\n",
       " 'of',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'gradually',\n",
       " 'the',\n",
       " 'shackles',\n",
       " 'of',\n",
       " 'slavery',\n",
       " 'are',\n",
       " 'being',\n",
       " 'broken',\n",
       " 'by',\n",
       " 't',\n",
       " 'he',\n",
       " 'forces',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'all',\n",
       " 'of',\n",
       " 'us',\n",
       " 'are',\n",
       " 'praying',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'is',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'the',\n",
       " 'armies',\n",
       " 'of',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'are',\n",
       " 'bringing',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'hitler',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'to',\n",
       " 'dominate',\n",
       " 'the',\n",
       " 'world',\n",
       " 'tokyo',\n",
       " 'rocks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'weight',\n",
       " 'of',\n",
       " 'our',\n",
       " 'bombs',\n",
       " 'the',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'united',\n",
       " 'nations',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'in',\n",
       " 'no',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'our',\n",
       " 'departed',\n",
       " 'commander',\n",
       " 'in',\n",
       " 'chief',\n",
       " 'we',\n",
       " 'are',\n",
       " 'now',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'our',\n",
       " 'part',\n",
       " 'of',\n",
       " 'that',\n",
       " 'strategy',\n",
       " 'under',\n",
       " 'the',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'admiral',\n",
       " 'leahy',\n",
       " 'general',\n",
       " 'marshall',\n",
       " 'a',\n",
       " 'dmiral',\n",
       " 'king',\n",
       " 'general',\n",
       " 'arnold',\n",
       " 'general',\n",
       " 'eisenhower',\n",
       " 'admiral',\n",
       " 'nimitz',\n",
       " 'and',\n",
       " 'general',\n",
       " 'macarthur',\n",
       " 'i',\n",
       " 'want',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'to',\n",
       " 'know',\n",
       " 'that',\n",
       " 'this',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'and',\n",
       " 'will',\n",
       " 'and',\n",
       " 'unhampered',\n",
       " 'our',\n",
       " 'debt',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'and',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'in',\n",
       " 'the',\n",
       " 'service',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'repaid',\n",
       " 'they',\n",
       " 'have',\n",
       " 'earned',\n",
       " 'our',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'america',\n",
       " 'will',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'their',\n",
       " 'sacrifices',\n",
       " 'because',\n",
       " 'of',\n",
       " 'these',\n",
       " 'sacrifices',\n",
       " 'the',\n",
       " 'dawn',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'its',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'the',\n",
       " 'horizon',\n",
       " 'our',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'to',\n",
       " 'our',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'in',\n",
       " 'search',\n",
       " 'of',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'for',\n",
       " 'those',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'they',\n",
       " 'risked',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'we',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'that',\n",
       " 'such',\n",
       " 'rights',\n",
       " 'can',\n",
       " 'be',\n",
       " 'preserved',\n",
       " 'only',\n",
       " 'by',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'the',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'of',\n",
       " 'liberty',\n",
       " 'within',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'after',\n",
       " 'i',\n",
       " 'took',\n",
       " 'the',\n",
       " 'oath',\n",
       " 'of',\n",
       " 'office',\n",
       " 'i',\n",
       " 'announced',\n",
       " 'that',\n",
       " 'the',\n",
       " 'san',\n",
       " 'francisco',\n",
       " 'conference',\n",
       " 'would',\n",
       " 'proceed',\n",
       " 'we',\n",
       " 'will',\n",
       " 'face',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'peace',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(tokens):\n",
    "    return [\n",
    "        token.lower()\n",
    "        for token in tokens\n",
    "        if token.isalpha()\n",
    "    ]\n",
    "normalize(tokens_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a5e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'harry',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'before',\n",
       " 'a',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'president',\n",
       " 'members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'congress',\n",
       " 'it',\n",
       " 'is']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "normalized_spacy = [token.text.lower() for token in doc if token.is_alpha]\n",
    "normalized_spacy[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b62c0",
   "metadata": {},
   "source": [
    "## Part 6 â€“ Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff405521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'harry',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'president',\n",
       " 'members',\n",
       " 'congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friends',\n",
       " 'colleagues',\n",
       " 'congress',\n",
       " 'united',\n",
       " 'states']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_nltk = [t for t in normalized_nltk if t not in stop_words]\n",
    "filtered_nltk[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d98963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['president',\n",
       " 'harry',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'president',\n",
       " 'members',\n",
       " 'congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friends',\n",
       " 'colleagues',\n",
       " 'congress',\n",
       " 'united',\n",
       " 'states']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filtered_spacy = [t for t in normalized_spacy if not nlp.vocab[t].is_stop]\n",
    "filtered_spacy[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d074b38",
   "metadata": {},
   "source": [
    "ðŸ“Œ Stop words are common words that often add little semantic meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438fcbe",
   "metadata": {},
   "source": [
    "## Part 7 â€“ Vocabulary and Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b8f7d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abiding',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'abroad',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'aching',\n",
       " 'across',\n",
       " 'address',\n",
       " 'admiral',\n",
       " 'aggressors',\n",
       " 'ahead',\n",
       " 'allies',\n",
       " 'almighty',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'announced',\n",
       " 'another',\n",
       " 'appeal',\n",
       " 'april',\n",
       " 'armed',\n",
       " 'armies',\n",
       " 'arnold',\n",
       " 'ask',\n",
       " 'assigned',\n",
       " 'assist',\n",
       " 'assisting',\n",
       " 'assumed',\n",
       " 'assure',\n",
       " 'avert',\n",
       " 'axis',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'barriers',\n",
       " 'based',\n",
       " 'battlefields',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'beloved',\n",
       " 'benefit',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'bitter',\n",
       " 'blood',\n",
       " 'bombs',\n",
       " 'brave',\n",
       " 'breakers',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broken',\n",
       " 'build',\n",
       " 'call',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'casts',\n",
       " 'cease',\n",
       " 'certain',\n",
       " 'champion',\n",
       " 'characteristic',\n",
       " 'cherish',\n",
       " 'chief',\n",
       " 'civilization',\n",
       " 'colleagues',\n",
       " 'color',\n",
       " 'come',\n",
       " 'comfort',\n",
       " 'commander',\n",
       " 'common',\n",
       " 'complete',\n",
       " 'complicated',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'conflict',\n",
       " 'congress',\n",
       " 'conscious',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'cooperation',\n",
       " 'costs',\n",
       " 'could',\n",
       " 'country',\n",
       " 'courage',\n",
       " 'creating',\n",
       " 'creed',\n",
       " 'crew',\n",
       " 'criminals',\n",
       " 'crushed',\n",
       " 'dangerous',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deadly',\n",
       " 'debt',\n",
       " 'decency',\n",
       " 'deciding',\n",
       " 'decisive',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defeatism',\n",
       " 'defend',\n",
       " 'defenders',\n",
       " 'defense',\n",
       " 'delano',\n",
       " 'delayed',\n",
       " 'demand',\n",
       " 'democratic',\n",
       " 'departed',\n",
       " 'depend',\n",
       " 'depending',\n",
       " 'despair',\n",
       " 'destroy',\n",
       " 'determination',\n",
       " 'determined',\n",
       " 'devoid',\n",
       " 'devoted',\n",
       " 'dictates',\n",
       " 'died',\n",
       " 'differences',\n",
       " 'difficult',\n",
       " 'direction',\n",
       " 'discern',\n",
       " 'distant',\n",
       " 'divine',\n",
       " 'dmiral',\n",
       " 'dominate',\n",
       " 'domination',\n",
       " 'doomed',\n",
       " 'doubt',\n",
       " 'dreams',\n",
       " 'due',\n",
       " 'durable',\n",
       " 'duties',\n",
       " 'duty',\n",
       " 'e',\n",
       " 'earned',\n",
       " 'earth',\n",
       " 'ease',\n",
       " 'economic',\n",
       " 'efforts',\n",
       " 'eisenhower',\n",
       " 'eloquent',\n",
       " 'eloquently',\n",
       " 'employment',\n",
       " 'end',\n",
       " 'ends',\n",
       " 'enduring',\n",
       " 'enemies',\n",
       " 'energy',\n",
       " 'enforce',\n",
       " 'enlightened',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'essential',\n",
       " 'eternal',\n",
       " 'even',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'except',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'face',\n",
       " 'faced',\n",
       " 'fact',\n",
       " 'fail',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'fallen',\n",
       " 'far',\n",
       " 'fatalism',\n",
       " 'fate',\n",
       " 'fathers',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'fellow',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'finest',\n",
       " 'fit',\n",
       " 'force',\n",
       " 'forces',\n",
       " 'forefathers',\n",
       " 'forget',\n",
       " 'fortunately',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'foundation',\n",
       " 'francisco',\n",
       " 'franklin',\n",
       " 'freedom',\n",
       " 'frequently',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'full',\n",
       " 'fundamental',\n",
       " 'futile',\n",
       " 'future',\n",
       " 'general',\n",
       " 'generations',\n",
       " 'geographical',\n",
       " 'germany',\n",
       " 'ghastly',\n",
       " 'give',\n",
       " 'gleam',\n",
       " 'glorious',\n",
       " 'go',\n",
       " 'god',\n",
       " 'going',\n",
       " 'good',\n",
       " 'gradually',\n",
       " 'grand',\n",
       " 'gratitude',\n",
       " 'grave',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greedy',\n",
       " 'guidance',\n",
       " 'guilty',\n",
       " 'harbor',\n",
       " 'hard',\n",
       " 'harmony',\n",
       " 'harry',\n",
       " 'heart',\n",
       " 'hearts',\n",
       " 'heavy',\n",
       " 'help',\n",
       " 'heritage',\n",
       " 'heroic',\n",
       " 'highest',\n",
       " 'hitler',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hopeless',\n",
       " 'horizon',\n",
       " 'horrible',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'however',\n",
       " 'human',\n",
       " 'humanity',\n",
       " 'humbly',\n",
       " 'humility',\n",
       " 'ideals',\n",
       " 'ill',\n",
       " 'impossible',\n",
       " 'improve',\n",
       " 'impunity',\n",
       " 'inadequate',\n",
       " 'increased',\n",
       " 'indicates',\n",
       " 'individual',\n",
       " 'inevitable',\n",
       " 'infinite',\n",
       " 'insist',\n",
       " 'international',\n",
       " 'ion',\n",
       " 'japan',\n",
       " 'jeopardize',\n",
       " 'joint',\n",
       " 'judge',\n",
       " 'justice',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'kindly',\n",
       " 'king',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'labored',\n",
       " 'laid',\n",
       " 'large',\n",
       " 'lasting',\n",
       " 'law',\n",
       " 'laws',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leadership',\n",
       " 'leahy',\n",
       " 'learn',\n",
       " 'learned',\n",
       " 'left',\n",
       " 'less',\n",
       " 'let',\n",
       " 'liberation',\n",
       " 'liberty',\n",
       " 'life',\n",
       " 'like',\n",
       " 'live',\n",
       " 'lived',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'long',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'lord',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'macarthur',\n",
       " 'machi',\n",
       " 'machinery',\n",
       " 'made',\n",
       " 'maintain',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'marshall',\n",
       " 'mastered',\n",
       " 'may',\n",
       " 'measure',\n",
       " 'members',\n",
       " 'memory',\n",
       " 'men',\n",
       " 'merely',\n",
       " 'method',\n",
       " 'might',\n",
       " 'military',\n",
       " 'millions',\n",
       " 'mind',\n",
       " 'misunderstanding',\n",
       " 'misunderstood',\n",
       " 'moment',\n",
       " 'momentary',\n",
       " 'mortal',\n",
       " 'mountain',\n",
       " 'moved',\n",
       " 'moving',\n",
       " 'much',\n",
       " 'must',\n",
       " 'muster',\n",
       " 'mutual',\n",
       " 'name',\n",
       " 'nation',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'naval',\n",
       " 'necessary',\n",
       " 'necessity',\n",
       " 'need',\n",
       " 'nery',\n",
       " 'never',\n",
       " 'new',\n",
       " 'nimitz',\n",
       " 'noble',\n",
       " 'nothing',\n",
       " 'oath',\n",
       " 'obligations',\n",
       " 'odds',\n",
       " 'offered',\n",
       " 'office',\n",
       " 'one',\n",
       " 'opponents',\n",
       " 'opportunity',\n",
       " 'order',\n",
       " 'organization',\n",
       " 'outlook',\n",
       " 'overwhelming',\n",
       " 'part',\n",
       " 'partial',\n",
       " 'party',\n",
       " 'passage',\n",
       " 'passing',\n",
       " 'past',\n",
       " 'path',\n",
       " 'pause',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'peace',\n",
       " 'peaceful',\n",
       " 'people',\n",
       " 'permit',\n",
       " 'pilot',\n",
       " 'plan',\n",
       " 'plot',\n",
       " 'political',\n",
       " 'possible',\n",
       " 'possibly',\n",
       " 'power',\n",
       " 'powerful',\n",
       " 'powers',\n",
       " 'pray',\n",
       " 'prayer',\n",
       " 'praying',\n",
       " 'preserve',\n",
       " 'preserved',\n",
       " 'president',\n",
       " 'prevented',\n",
       " 'price',\n",
       " 'problems',\n",
       " 'proceed',\n",
       " 'proclaimed',\n",
       " 'product',\n",
       " 'progress',\n",
       " 'proportions',\n",
       " 'prosperity',\n",
       " 'protected',\n",
       " 'provided',\n",
       " 'public',\n",
       " 'punish',\n",
       " 'pursue',\n",
       " 'race',\n",
       " 'rapidly',\n",
       " 'rational',\n",
       " 'real',\n",
       " 'really',\n",
       " 'regardless',\n",
       " 'relations',\n",
       " 'relaxation',\n",
       " 'religious',\n",
       " 'remain',\n",
       " 'remains',\n",
       " 'repaid',\n",
       " 'require',\n",
       " 'requires',\n",
       " 'resistance',\n",
       " 'resolute',\n",
       " 'respite',\n",
       " 'respon',\n",
       " 'responsibilities',\n",
       " 'responsibility',\n",
       " 'rest',\n",
       " 'resting',\n",
       " 'retained',\n",
       " 'retreat',\n",
       " 'reverent',\n",
       " 'rights',\n",
       " 'risked',\n",
       " 'rocks',\n",
       " 'roosevelt',\n",
       " 'rugged',\n",
       " 'sacrifice',\n",
       " 'sacrifices',\n",
       " 'safely',\n",
       " 'safety',\n",
       " 'salvation',\n",
       " 'san',\n",
       " 'search',\n",
       " 'secret',\n",
       " 'secured',\n",
       " 'security',\n",
       " 'see',\n",
       " 'seek',\n",
       " 'seen',\n",
       " 'servant',\n",
       " 'serve',\n",
       " 'service',\n",
       " 'session',\n",
       " 'settle',\n",
       " 'settlement',\n",
       " 'shackles',\n",
       " 'shadow',\n",
       " 'shake',\n",
       " 'shall',\n",
       " 'shed',\n",
       " 'ship',\n",
       " 'shirk',\n",
       " 'shores',\n",
       " 'showed',\n",
       " 'shrinking',\n",
       " 'sibility',\n",
       " 'silence',\n",
       " 'slavery',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'social',\n",
       " 'solely',\n",
       " 'solomon',\n",
       " 'something',\n",
       " 'soul',\n",
       " 'sound',\n",
       " 'speaker',\n",
       " 'special',\n",
       " 'speedy',\n",
       " 'spirit',\n",
       " 'staggering',\n",
       " 'stand',\n",
       " 'standards',\n",
       " 'states',\n",
       " 'still',\n",
       " 'strategy',\n",
       " 'strength',\n",
       " 'strong',\n",
       " 'struggle',\n",
       " 'submission',\n",
       " 'successive',\n",
       " 'suffering',\n",
       " 'sufficient',\n",
       " 'support',\n",
       " 'supreme',\n",
       " 'surely',\n",
       " 'surrender',\n",
       " 'take',\n",
       " 'task',\n",
       " 'tasks',\n",
       " 'temporary',\n",
       " 'terms',\n",
       " 'terrible',\n",
       " 'th',\n",
       " 'therefore',\n",
       " 'though',\n",
       " 'thoughtful',\n",
       " 'threat',\n",
       " 'throughout',\n",
       " 'thrust',\n",
       " 'thy',\n",
       " 'time',\n",
       " 'today',\n",
       " 'tokyo',\n",
       " 'tolerance',\n",
       " 'toll',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'trade',\n",
       " 'traffic',\n",
       " 'tragic',\n",
       " 'tremendous',\n",
       " 'tribute',\n",
       " 'triumph',\n",
       " 'truman',\n",
       " 'turn',\n",
       " 'tyrants',\n",
       " 'ultimately',\n",
       " 'unconscious',\n",
       " 'understanding',\n",
       " 'undying',\n",
       " 'unhampered',\n",
       " 'united',\n",
       " 'unjustified',\n",
       " 'unless',\n",
       " 'unnecessary',\n",
       " 'unpunished',\n",
       " 'unquestionably',\n",
       " 'untold',\n",
       " 'unwilling',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'valiant',\n",
       " 'vestige',\n",
       " 'victory',\n",
       " 'vigilance',\n",
       " 'violated',\n",
       " 'vision',\n",
       " 'void',\n",
       " 'w',\n",
       " 'want',\n",
       " 'war',\n",
       " 'warned',\n",
       " 'wars',\n",
       " 'way',\n",
       " 'weapon',\n",
       " 'weight',\n",
       " 'well',\n",
       " 'wisdom',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'without',\n",
       " 'women',\n",
       " 'words',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worthy',\n",
       " 'would',\n",
       " 'yearn',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'yield',\n",
       " 'youth']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "\n",
    "for doc in normalized_nltk:\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    tokens = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "vocabulary = sorted(set(all_tokens))\n",
    "print(len(vocabulary))\n",
    "vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f680b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543,\n",
       " ['abiding',\n",
       "  'abject',\n",
       "  'able',\n",
       "  'abroad',\n",
       "  'achieve',\n",
       "  'achieved',\n",
       "  'aching',\n",
       "  'address',\n",
       "  'admiral',\n",
       "  'advantage',\n",
       "  'aggressors',\n",
       "  'ahead',\n",
       "  'allies',\n",
       "  'almighty',\n",
       "  'america',\n",
       "  'american',\n",
       "  'americans',\n",
       "  'announced',\n",
       "  'appeal',\n",
       "  'april',\n",
       "  'armed',\n",
       "  'armies',\n",
       "  'arnold',\n",
       "  'ask',\n",
       "  'assigned',\n",
       "  'assist',\n",
       "  'assisting',\n",
       "  'assumed',\n",
       "  'assure',\n",
       "  'avert'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary from corpus\n",
    "vocabulary = sorted(set(filtered_spacy))\n",
    "len(vocabulary), vocabulary[:30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4acb8d",
   "metadata": {},
   "source": [
    "ðŸ“Œ The vocabulary is the set of unique tokens in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aa861aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peace', 23),\n",
       " ('world', 20),\n",
       " ('nations', 12),\n",
       " ('america', 11),\n",
       " ('people', 10),\n",
       " ('hope', 10),\n",
       " ('united', 8),\n",
       " ('freedom', 7),\n",
       " ('great', 6),\n",
       " ('shall', 6),\n",
       " ('man', 5),\n",
       " ('justice', 5),\n",
       " ('victory', 5),\n",
       " ('entire', 5),\n",
       " ('defense', 5)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Counter(filtered_spacy).most_common(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4f2f9",
   "metadata": {},
   "source": [
    "# Stemming vs Lemmatization\n",
    "\n",
    "Stemming and lemmatization are both normalization techniques, but they make very different trade-offs.\n",
    "\n",
    "Stemming is fast and rule-based but can distort meaning\n",
    "\n",
    "Lemmatization is slower but linguistically informed\n",
    "\n",
    "In industry, the choice depends on task, domain, and interpretability requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f4d0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 'presid'),\n",
       " ('harry', 'harri'),\n",
       " ('truman', 'truman'),\n",
       " ('address', 'address'),\n",
       " ('joint', 'joint'),\n",
       " ('session', 'session'),\n",
       " ('congress', 'congress'),\n",
       " ('april', 'april'),\n",
       " ('speaker', 'speaker'),\n",
       " ('president', 'presid'),\n",
       " ('members', 'member'),\n",
       " ('congress', 'congress'),\n",
       " ('heavy', 'heavi'),\n",
       " ('heart', 'heart'),\n",
       " ('stand', 'stand'),\n",
       " ('friends', 'friend'),\n",
       " ('colleagues', 'colleagu'),\n",
       " ('congress', 'congress'),\n",
       " ('united', 'unit'),\n",
       " ('states', 'state'),\n",
       " ('yesterday', 'yesterday'),\n",
       " ('laid', 'laid'),\n",
       " ('rest', 'rest'),\n",
       " ('mortal', 'mortal'),\n",
       " ('remains', 'remain'),\n",
       " ('beloved', 'belov'),\n",
       " ('president', 'presid'),\n",
       " ('franklin', 'franklin'),\n",
       " ('delano', 'delano'),\n",
       " ('roosevelt', 'roosevelt')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming with NLTK\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_tokens = [stemmer.stem(t) for t in filtered_nltk[:30]]\n",
    "list(zip(filtered_nltk[:30], stemmed_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b89db",
   "metadata": {},
   "source": [
    "â€œdemocracyâ€ â†’ â€œdemocraciâ€\n",
    "\n",
    "stems are not necessarily real words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da72d7",
   "metadata": {},
   "source": [
    "### spaCy does not include a built-in stemmer by default.\n",
    "\n",
    "This is not a limitation. It is a design choice.\n",
    "\n",
    "spaCy prioritizes:\n",
    "\n",
    "- linguistically informed processing\n",
    "\n",
    "- lemmatization over stemming\n",
    "\n",
    "However, in real pipelines, you can still perform stemming alongside spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d5612fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presid',\n",
       " 'harri',\n",
       " 'truman',\n",
       " 'address',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'congress',\n",
       " 'april',\n",
       " 'speaker',\n",
       " 'presid',\n",
       " 'member',\n",
       " 'congress',\n",
       " 'heavi',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friend',\n",
       " 'colleagu',\n",
       " 'congress',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'yesterday',\n",
       " 'laid',\n",
       " 'rest',\n",
       " 'mortal',\n",
       " 'remain',\n",
       " 'belov',\n",
       " 'presid',\n",
       " 'franklin',\n",
       " 'delano',\n",
       " 'roosevelt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "doc_spacy = nlp(raw_text)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Use spaCy for tokenization, NLTK for stemming\n",
    "stemmed_spacy_tokens = [\n",
    "    stemmer.stem(token.text.lower())\n",
    "    for token in doc_spacy\n",
    "    if token.is_alpha and not token.is_stop\n",
    "]\n",
    "\n",
    "stemmed_spacy_tokens[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39343b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'TRUMAN',\n",
       " 'ADDRESS',\n",
       " 'JOINT',\n",
       " 'session',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Speaker',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friend',\n",
       " 'colleague',\n",
       " 'Congress',\n",
       " 'United',\n",
       " 'States',\n",
       " 'yesterday',\n",
       " 'lay',\n",
       " 'rest',\n",
       " 'mortal',\n",
       " 'remain',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization with spaCy\n",
    "# Always recreate the spaCy Doc explicitly\n",
    "doc_spacy = nlp(raw_text)\n",
    "\n",
    "lemmatized_tokens = [\n",
    "    token.lemma_\n",
    "    for token in doc_spacy\n",
    "    if token.is_alpha and not token.is_stop\n",
    "]\n",
    "\n",
    "lemmatized_tokens[:30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a190ce",
   "metadata": {},
   "source": [
    "NLTK does support lemmatization, but it requires:\n",
    "\n",
    "- a lemmatizer\n",
    "\n",
    "- part-of-speech information to work well\n",
    "\n",
    "By default, NLTKâ€™s lemmatizer assumes nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "947fe41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('president', 'president'),\n",
       " ('harry', 'harry'),\n",
       " ('truman', 'truman'),\n",
       " ('address', 'address'),\n",
       " ('joint', 'joint'),\n",
       " ('session', 'session'),\n",
       " ('congress', 'congress'),\n",
       " ('april', 'april'),\n",
       " ('speaker', 'speaker'),\n",
       " ('president', 'president'),\n",
       " ('members', 'member'),\n",
       " ('congress', 'congress'),\n",
       " ('heavy', 'heavy'),\n",
       " ('heart', 'heart'),\n",
       " ('stand', 'stand'),\n",
       " ('friends', 'friend'),\n",
       " ('colleagues', 'colleague'),\n",
       " ('congress', 'congress'),\n",
       " ('united', 'united'),\n",
       " ('states', 'state'),\n",
       " ('yesterday', 'yesterday'),\n",
       " ('laid', 'laid'),\n",
       " ('rest', 'rest'),\n",
       " ('mortal', 'mortal'),\n",
       " ('remains', 'remains'),\n",
       " ('beloved', 'beloved'),\n",
       " ('president', 'president'),\n",
       " ('franklin', 'franklin'),\n",
       " ('delano', 'delano'),\n",
       " ('roosevelt', 'roosevelt')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_nltk = [\n",
    "    lemmatizer.lemmatize(t)\n",
    "    for t in filtered_nltk[:30]\n",
    "]\n",
    "\n",
    "list(zip(filtered_nltk[:30], lemmatized_nltk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c709b50",
   "metadata": {},
   "source": [
    "Notice that many verbs are not lemmatized correctly.\n",
    "This is because NLTKâ€™s lemmatizer defaults to noun POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "263d48f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('president', 'presid', 'president'),\n",
       " ('harry', 'harri', 'harry'),\n",
       " ('truman', 'truman', 'truman'),\n",
       " ('address', 'address', 'address'),\n",
       " ('joint', 'joint', 'joint'),\n",
       " ('session', 'session', 'session'),\n",
       " ('congress', 'congress', 'congress'),\n",
       " ('april', 'april', 'april'),\n",
       " ('speaker', 'speaker', 'speaker'),\n",
       " ('president', 'presid', 'president'),\n",
       " ('members', 'member', 'member'),\n",
       " ('congress', 'congress', 'congress'),\n",
       " ('heavy', 'heavi', 'heavy'),\n",
       " ('heart', 'heart', 'heart'),\n",
       " ('stand', 'stand', 'stand'),\n",
       " ('friends', 'friend', 'friend'),\n",
       " ('colleagues', 'colleagu', 'colleague'),\n",
       " ('congress', 'congress', 'congress'),\n",
       " ('united', 'unit', 'united'),\n",
       " ('states', 'state', 'state')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = list(zip(\n",
    "    filtered_spacy[:20],\n",
    "    stemmed_spacy_tokens[:20],\n",
    "    lemmatized_nltk[:20]\n",
    "))\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd8059",
   "metadata": {},
   "source": [
    "# From Words to Subwords: Byte Pair Encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98784c3c",
   "metadata": {},
   "source": [
    "So far, we have treated words as the basic unit of meaning.\n",
    "Modern NLP systems often go one step further and operate on subword units.\n",
    "\n",
    "One of the most common subword tokenization methods is Byte Pair Encoding (BPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb140f",
   "metadata": {},
   "source": [
    "In large corpora like the State of the Union addresses, word-level tokenization creates several problems:\n",
    "\n",
    "Rare words appear very infrequently\n",
    "\n",
    "New words appear over time (e.g. cybersecurity, biotechnology)\n",
    "\n",
    "Related words are treated as completely separate tokens\n",
    "\n",
    "Subword tokenization solves this by breaking words into frequently occurring pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c59ff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['democracy',\n",
       " 'democratic',\n",
       " 'democratization',\n",
       " 'economy',\n",
       " 'economic',\n",
       " 'economics']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a small subset of real policy-related words that appear in State of the Union speeches.\n",
    "\n",
    "words = [\n",
    "    \"democracy\",\n",
    "    \"democratic\",\n",
    "    \"democratization\",\n",
    "    \"economy\",\n",
    "    \"economic\",\n",
    "    \"economics\"\n",
    "]\n",
    "\n",
    "words\n",
    "# At the word level, all of these are treated as separate tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1122e16",
   "metadata": {},
   "source": [
    "## Step 1 â€“ Character-Level Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f2b25",
   "metadata": {},
   "source": [
    "BPE starts by representing each word as a sequence of characters\n",
    "(with a special end-of-word marker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3127d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['d', 'e', 'm', 'o', 'c', 'r', 'a', 'c', 'y', '</w>'],\n",
       " ['d', 'e', 'm', 'o', 'c', 'r', 'a', 't', 'i', 'c', '</w>'],\n",
       " ['d',\n",
       "  'e',\n",
       "  'm',\n",
       "  'o',\n",
       "  'c',\n",
       "  'r',\n",
       "  'a',\n",
       "  't',\n",
       "  'i',\n",
       "  'z',\n",
       "  'a',\n",
       "  't',\n",
       "  'i',\n",
       "  'o',\n",
       "  'n',\n",
       "  '</w>'],\n",
       " ['e', 'c', 'o', 'n', 'o', 'm', 'y', '</w>'],\n",
       " ['e', 'c', 'o', 'n', 'o', 'm', 'i', 'c', '</w>'],\n",
       " ['e', 'c', 'o', 'n', 'o', 'm', 'i', 'c', 's', '</w>']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tokens = [list(word) + [\"</w>\"] for word in words]\n",
    "char_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80846fee",
   "metadata": {},
   "source": [
    "## Step 2 â€“ Count Frequent Character Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70412b",
   "metadata": {},
   "source": [
    "BPE repeatedly merges the most frequent adjacent character pairs across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47f9287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('o', 'n'), 4),\n",
       " (('d', 'e'), 3),\n",
       " (('e', 'm'), 3),\n",
       " (('m', 'o'), 3),\n",
       " (('o', 'c'), 3),\n",
       " (('c', 'r'), 3),\n",
       " (('r', 'a'), 3),\n",
       " (('a', 't'), 3),\n",
       " (('t', 'i'), 3),\n",
       " (('i', 'c'), 3)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pair_counts = Counter()\n",
    "\n",
    "for word in char_tokens:\n",
    "    for i in range(len(word) - 1):\n",
    "        pair = (word[i], word[i+1])\n",
    "        pair_counts[pair] += 1\n",
    "\n",
    "pair_counts.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbf90b",
   "metadata": {},
   "source": [
    "## Step 3 â€“ Merge Frequent Pairs (Conceptual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20dd120",
   "metadata": {},
   "source": [
    "The most frequent pair is ('o', 'n').\n",
    "BPE merges it into a new token: \"on\".\n",
    "\n",
    "This process repeats many times, gradually forming meaningful subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bad9d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['democr', 'acy</w>'],\n",
       " ['democr', 'atic</w>'],\n",
       " ['democr', 'atization</w>'],\n",
       " ['econ', 'omy</w>'],\n",
       " ['econ', 'omic</w>'],\n",
       " ['econ', 'omics</w>']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_tokens_example = [\n",
    "    [\"democr\", \"acy</w>\"],\n",
    "    [\"democr\", \"atic</w>\"],\n",
    "    [\"democr\", \"atization</w>\"],\n",
    "    [\"econ\", \"omy</w>\"],\n",
    "    [\"econ\", \"omic</w>\"],\n",
    "    [\"econ\", \"omics</w>\"]\n",
    "]\n",
    "\n",
    "bpe_tokens_example\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AIG230)",
   "language": "python",
   "name": "aig230-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
